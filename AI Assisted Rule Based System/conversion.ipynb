{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import scipy.io as sio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the HIHD dataset\n",
    "dataset_path = r\"C:\\Users\\hp\\Downloads\\HR_IMU_falldetection_dataset-master\\HR_IMU_falldetection_dataset-master\"\n",
    "dataset = []\n",
    "missing_files = []  # Track missing/corrupt files\n",
    "invalid_files = []  # Track files missing required data\n",
    "total_expected_files = 0  # Track expected file count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(ax, ay, az, heart):\n",
    "    return {\n",
    "        'ax_mean': np.mean(ax), 'ay_mean': np.mean(ay), 'az_mean': np.mean(az),\n",
    "        'ax_std': np.std(ax), 'ay_std': np.std(ay), 'az_std': np.std(az),\n",
    "        'smv': np.mean(np.sqrt(ax**2 + ay**2 + az**2)),  # Signal Magnitude Vector\n",
    "        'heart_mean': np.mean(heart), 'heart_std': np.std(heart)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_count = 0  # Track processed files\n",
    "\n",
    "# Traverse subjects\n",
    "for subject in os.listdir(dataset_path):\n",
    "    subject_path = os.path.join(dataset_path, subject)\n",
    "    if os.path.isdir(subject_path):  \n",
    "        for label_folder in ['fall', 'non-fall']:  # Ensure lowercase folder names\n",
    "            label_path = os.path.join(subject_path, label_folder)\n",
    "            \n",
    "            if os.path.isdir(label_path):\n",
    "                # Count how many .mat files exist\n",
    "                mat_files = [f for f in os.listdir(label_path) if f.endswith('.mat')]\n",
    "                total_expected_files += len(mat_files)  # Track total expected files\n",
    "                \n",
    "                for scenario_file in mat_files:\n",
    "                    scenario_path = os.path.join(label_path, scenario_file)\n",
    "                    try:\n",
    "                        data = sio.loadmat(scenario_path)\n",
    "\n",
    "                        # Extract required data\n",
    "                        ax = data.get('ax', np.array([])).flatten()\n",
    "                        ay = data.get('ay', np.array([])).flatten()\n",
    "                        az = data.get('az', np.array([])).flatten()\n",
    "                        heart = data.get('heart', np.array([])).flatten()\n",
    "\n",
    "                        # Check if all necessary data exists\n",
    "                        if ax.size > 0 and ay.size > 0 and az.size > 0 and heart.size > 0:\n",
    "                            features = extract_features(ax, ay, az, heart)\n",
    "                            features['label'] = 1 if label_folder == 'fall' else 0\n",
    "                            features['subject'] = subject\n",
    "                            features['scenario'] = scenario_file\n",
    "                            dataset.append(features)\n",
    "                            file_count += 1\n",
    "                        else:\n",
    "                            invalid_files.append(scenario_path)  # Log incomplete files\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing {scenario_path}: {e}\")\n",
    "                        missing_files.append(scenario_path)  # Log unreadable files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Expected Files: 349\n",
      "Total Processed Files: 349\n",
      "Missing/Unreadable Files: 0\n",
      "Invalid Data Files (Missing ax, ay, az, or heart): 0\n"
     ]
    }
   ],
   "source": [
    "# Convert the dataset list to a DataFrame\n",
    "df = pd.DataFrame(dataset)\n",
    "\n",
    "# Save the dataset as a CSV file\n",
    "output_csv_path = r\"C:\\Users\\hp\\Downloads\\HR_IMU_falldetection_dataset-master\\HR_IMU_falldetection_dataset-master\\HIHD.csv\"\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Debug: Print missing/corrupt file report\n",
    "print(f\"Total Expected Files: {total_expected_files}\")\n",
    "print(f\"Total Processed Files: {file_count}\")\n",
    "print(f\"Missing/Unreadable Files: {len(missing_files)}\")\n",
    "print(f\"Invalid Data Files (Missing ax, ay, az, or heart): {len(invalid_files)}\")\n",
    "\n",
    "if missing_files:\n",
    "    print(\"Unreadable Files:\", missing_files)\n",
    "if invalid_files:\n",
    "    print(\"Files Missing Data:\", invalid_files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
